#!/usr/bin/env python3
"""
Official Example Test for M0-M1: TVMScript Parser Enhancement + Complete BasePyModule

This test demonstrates:
- M0a: Python functions with @I.pyfunc decorator
- M0b: IRModule subclassing BasePyModule
- M1a: DLPack conversion between PyTorch tensors and TVM NDArray
- Cross-function calls between Python, TIR, and Relax functions
"""

import torch
import torch.nn.functional as F

import tvm
from tvm import relax, tir
from tvm.script import ir as I
from tvm.script import relax as R
from tvm.script import tir as T
from tvm.relax import BasePyModule

@I.ir_module
class IRModuleWithPyFunc(BasePyModule):
    """Example IRModule with Python function.
    The base class BasePyModule implements the logic of cross-function calls
    and JIT compilation in Python.
    We only allow Python functions in IRModules that subclass the BasePyModule.
    """

    @I.pyfunc
    def main(self, x: torch.Tensor, w: torch.Tensor) -> torch.Tensor:
        n = x.shape[0]
        lv = self.call_tir(self.matmul, [x, w], out_sinfo=R.Tensor((n, 20), "float32"))
        lv1 = F.relu(lv)
        lv2 = self.call_dps_packed("my_softmax", [lv1, 1], out_sinfo=R.Tensor((n, 20), "float32"))
        lv3 = self.my_identity_func(lv2)
        gv = lv3
        return gv

    @T.prim_func
    def matmul(
        var_A: T.handle,
        var_B: T.handle,
        var_C: T.handle,
    ):
        n = T.int32()
        A = T.match_buffer(var_A, (n, 16), "float32")
        B = T.match_buffer(var_B, (16, 20), "float32")
        C = T.match_buffer(var_C, (n, 20), "float32")
        for i, j, k in T.grid(n, 20, 16):
            with T.block("block"):
                vi, vj, vk = T.axis.remap("SSR", [i, j, k])
                with T.init():
                    C[vi, vj] = T.float32(0)
                C[vi, vj] = C[vi, vj] + A[vi, vk] * B[vk, vj]

    @I.pyfunc
    def my_identity_func(self, x: torch.Tensor) -> torch.Tensor:
        return x




def test_m0_tvmscript_parser_enhancement():
    """Test M0: TVMScript parser enhancement"""
    print("üß™ Testing M0: TVMScript Parser Enhancement")
    print("=" * 60)
    
    # Test M0a: Python functions with @I.pyfunc decorator
    print("M0a: Python functions with @I.pyfunc decorator")
    print("-" * 40)
    
    # After decoration, IRModuleWithPyFunc is an IRModule object, not a class
    # The pyfunc methods are already processed and stored in the IRModule
    print(f"‚úÖ IRModuleWithPyFunc type: {type(IRModuleWithPyFunc)}")
    
    if hasattr(IRModuleWithPyFunc, 'functions'):
        print("‚úÖ IRModule has functions attribute")
        # Check for ExternFunc nodes (Python functions)
        extern_funcs = []
        for gv, func in IRModuleWithPyFunc.functions_items():
            if hasattr(func, 'attrs') and func.attrs and 'is_pyfunc' in func.attrs:
                extern_funcs.append(gv.name_hint)
        print(f"‚úÖ Found {len(extern_funcs)} Python functions: {extern_funcs}")
    else:
        print("‚ùå IRModule missing functions attribute")
    
    # Test M0b: IRModule subclassing BasePyModule (already verified during decoration)
    print("\nM0b: IRModule subclassing BasePyModule")
    print("-" * 40)
    
    # This was already verified during decoration
    print("‚úÖ BasePyModule inheritance verified during decoration")
    print("‚úÖ Python functions allowed and processed")
    
    # Test M0c: TVMScript printing support
    print("\nM0c: TVMScript printing support")
    print("-" * 40)
    
    try:
        script_output = IRModuleWithPyFunc.script()
        print("‚úÖ script() method works correctly")
        print("üìú Script preview (first 200 chars):")
        print(script_output[:200] + "..." if len(script_output) > 200 else script_output)
    except Exception as e:
        print(f"‚ùå script() method failed: {e}")
    
    print("\n" + "=" * 60)


def test_m1_complete_base_py_module():
    """Test M1: Complete BasePyModule"""
    print("üß™ Testing M1: Complete BasePyModule")
    print("=" * 60)
    
    # Test M1a: DLPack conversion and cross-function calls
    print("M1a: DLPack conversion and cross-function calls")
    print("-" * 40)
    
    try:
        # Create device
        device = tvm.cpu()  # Use CPU for testing
        print(f"‚úÖ Created device: {device}")
        
        # Create Python module instance
        print("üîß Creating IRModuleWithPyFunc instance...")
        
        # Check if IRModuleWithPyFunc has a create_instance method
        print(f"üîç Debug: IRModuleWithPyFunc type: {type(IRModuleWithPyFunc)}")
        print(f"üîç Debug: has create_instance: {hasattr(IRModuleWithPyFunc, 'create_instance')}")
        print(f"üîç Debug: has __call__: {hasattr(IRModuleWithPyFunc, '__call__')}")
        
        # Additional debug: check the actual __call__ method
        if hasattr(IRModuleWithPyFunc, '__call__'):
            print(f"üîç Debug: IRModuleWithPyFunc.__call__ type: {type(IRModuleWithPyFunc.__call__)}")
            print(f"üîç Debug: IRModuleWithPyFunc.__call__: {IRModuleWithPyFunc.__call__}")
        
        if hasattr(IRModuleWithPyFunc, 'create_instance'):
            print("üîß Using create_instance method...")
            py_mod = IRModuleWithPyFunc.create_instance(device)
            print(f"‚úÖ Created instance using create_instance: {type(py_mod)}")
        elif hasattr(IRModuleWithPyFunc, '__call__'):
            print("üîß Using __call__ method...")
            py_mod = IRModuleWithPyFunc(device)
            print(f"‚úÖ Created instance using __call__: {type(py_mod)}")
        else:
            print("‚ùå No way to create instance found")
            return
        
        # Check if instance has required methods
        required_methods = ['main', 'call_tir', 'call_dps_packed']
        for method in required_methods:
            if hasattr(py_mod, method):
                print(f"‚úÖ Instance has method: {method}")
            else:
                print(f"‚ùå Instance missing method: {method}")
        
        # Test cross-function calls
        print("\nM1b: Testing cross-function calls")
        print("-" * 40)
        
        # Create test data
        n = 10  # Use smaller size for testing
        x = torch.randn(n, 16, dtype=torch.float32)
        w = torch.randn(16, 20, dtype=torch.float32)
        
        print(f"‚úÖ Created test tensors: x.shape={x.shape}, w.shape={w.shape}")
        
        # Test the main function
        print("üîß Calling py_mod.main(x, w)...")
        try:
            out = py_mod.main(x, w)
            print(f"‚úÖ main() call successful, output shape: {out.shape}")
            print(f"‚úÖ Output type: {type(out)}")
            
            # Verify output is PyTorch tensor
            if isinstance(out, torch.Tensor):
                print("‚úÖ Output is PyTorch tensor (DLPack conversion working)")
            else:
                print(f"‚ö†Ô∏è Output is not PyTorch tensor: {type(out)}")
                
        except Exception as e:
            print(f"‚ùå main() call failed: {e}")
            import traceback
            traceback.print_exc()
        
    except Exception as e:
        print(f"‚ùå Failed to create instance: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 60)


def test_integration():
    """Test complete integration of M0-M1"""
    print("üß™ Testing Complete Integration: M0 + M1")
    print("=" * 60)
    
    print("This test verifies that all components work together:")
    print("1. TVMScript parser enhancement (@I.pyfunc, inheritance)")
    print("2. BasePyModule functionality (DLPack, cross-function calls)")
    print("3. Seamless PyTorch integration")
    
    try:
        # Create instance
        device = tvm.cpu()
        
        # Check if IRModuleWithPyFunc has a create_instance method
        if hasattr(IRModuleWithPyFunc, 'create_instance'):
            py_mod = IRModuleWithPyFunc.create_instance(device)
        elif hasattr(IRModuleWithPyFunc, '__call__'):
            py_mod = IRModuleWithPyFunc(device)
        else:
            print("‚ùå No way to create instance found")
            return
        
        # Test data
        n = 5
        x = torch.randn(n, 16, dtype=torch.float32)
        w = torch.randn(16, 20, dtype=torch.float32)
        
        # Full pipeline test
        print("\nüîß Testing complete pipeline...")
        out = py_mod.main(x, w)
        
        print("‚úÖ Complete integration test PASSED!")
        print(f"   Input shapes: x={x.shape}, w={w.shape}")
        print(f"   Output shape: {out.shape}")
        print(f"   Output type: {type(out)}")
        
    except Exception as e:
        print(f"‚ùå Integration test failed: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 60)


def main():
    """Main test function"""
    print("üöÄ Official Example Test for M0-M1: TVMScript + BasePyModule")
    print("=" * 80)
    
    # Run all tests
    test_m0_tvmscript_parser_enhancement()
    test_m1_complete_base_py_module()
    test_integration()
    
    print("üéØ Test Summary:")
    print("M0: TVMScript parser enhancement - Python functions + BasePyModule inheritance")
    print("M1: Complete BasePyModule - DLPack conversion + cross-function calls")
    print("Integration: Seamless PyTorch tensor I/O with TVM backend")


if __name__ == "__main__":
    main()
