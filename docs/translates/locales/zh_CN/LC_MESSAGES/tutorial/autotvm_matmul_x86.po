# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020 - 2021, Apache Software Foundation
# This file is distributed under the same license as the tvm package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
# 
# Translators:
# HLearning, 2021
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: tvm 0.8.dev1734+gca660ba1e\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-10-12 10:06+0000\n"
"PO-Revision-Date: 2021-10-13 01:40+0000\n"
"Last-Translator: HLearning, 2021\n"
"Language-Team: Chinese (China) (https://www.transifex.com/TVMChinese/teams/124815/zh_CN/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: zh_CN\n"
"Plural-Forms: nplurals=1; plural=0;\n"

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:4
msgid ""
"Click :ref:`here <sphx_glr_download_tutorial_autotvm_matmul_x86.py>` to "
"download the full example code"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:13
msgid "Optimizing Operators with Schedule Templates and AutoTVM"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:14
msgid ""
"**Authors**: `Lianmin Zheng <https://github.com/merrymercy>`_, `Chris Hoge "
"<https://github.com/hogepodge>`_"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:18
msgid ""
"In this tutorial, we show how the TVM Tensor Expression (TE) language can be"
" used to write schedule templates that can be searched by AutoTVM to find "
"the optimal schedule. This process is called Auto-Tuning, which helps "
"automate the process of optimizing tensor computation."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:23
msgid ""
"This tutorial builds on the previous `tutorial on how to write a matrix "
"multiplication using TE <tensor_expr_get_started>`."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:26
msgid "There are two steps in auto-tuning."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:28
msgid "The first step is defining a search space."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:29
msgid ""
"The second step is running a search algorithm to explore through this space."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:31
msgid ""
"In this tutorial, you can learn how to perform these two steps in TVM. The "
"whole workflow is illustrated by a matrix multiplication example."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:35
msgid ""
"Note that this tutorial will not run on Windows or recent versions of macOS."
" To get it to run, you will need to wrap the body of this tutorial in a "
":code:`if __name__ == \"__main__\":` block."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:40
msgid "Install dependencies"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:41
msgid ""
"To use autotvm package in TVM, we need to install some extra dependencies."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:47
msgid ""
"To make TVM run faster in tuning, it is recommended to use cython as FFI of "
"TVM. In the root directory of TVM, execute:"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:55
msgid "Now return to python code. Begin by importing the required packages."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:79
msgid "Basic Matrix Multiplication with TE"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:80
msgid ""
"Recall the basic implementation of matrix multiplication using TE. We write "
"it down here with a few changes. We will wrap the multiplication in a python"
" function definition. For simplicity, we will focus our attention on a split"
" optimization, using a fixed value that defines the block size of the "
"reordering."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:119
msgid "Matrix Multiplication with AutoTVM"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:120
msgid ""
"In the previous schedule code, we use a constant \"8\" as the tiling factor."
" However, it might not be the best one because the best tiling factor "
"depends on real hardware environment and input shape."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:124
msgid ""
"If you want the schedule code to be portable across a wider range of input "
"shapes and target hardware, it is better to define a set of candidate values"
" and pick the best one according to the measurement results on target "
"hardware."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:129
msgid ""
"In autotvm, we can define a tunable parameter, or a \"knob\" for such kind "
"of value."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:133
msgid "A Basic Matrix Multiplication Template"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:134
msgid ""
"We begin with an example of how to create a tunable parameter set for the "
"block size of the `split` scheduling operation."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:177
msgid ""
"Here we make four modifications to the previous schedule code and get a "
"tunable \"template\". We can explain the modifications one by one."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:180
msgid "Use a decorator to mark this function as a simple template."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:181
msgid ""
"Get a config object: You can regard this :code:`cfg` as an argument of this "
"function but we obtain it in a different way. With this argument, this "
"function is no longer a deterministic schedule. Instead, we can pass "
"different configurations to this function and get different schedules. A "
"function that uses a configuration object like this is called a "
"\"template\"."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:187
msgid ""
"To make the template function more compact, we can do two things to define "
"the parameter search space within a single function."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:190
msgid ""
"Define a search space across a set values. This is done by making "
":code:`cfg` a :any:`ConfigSpace` object. It will collect all of the tunable "
"knobs in this function and build a search space from it."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:193
msgid ""
"Schedule according to an entity in this space. This is done by making "
":code:`cfg` a :any:`ConfigEntity` object. When it is a :any:`ConfigEntity`, "
"it will ignore all space definition API (namely, "
":code:`cfg.define_XXXXX(...)`). Instead, it will store deterministic values "
"for all tunable knobs, and we schedule according to these values."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:199
msgid ""
"During auto-tuning, we will first call this template with a "
":any:`ConfigSpace` object to build the search space. Then we call this "
"template with different :any:`ConfigEntity` in the built space to get "
"different schedules. Finally we will measure the code generated by different"
" schedules and pick the best one."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:205
msgid ""
"Define two tunable knobs. The first one is :code:`tile_y` with 5 possible "
"values. The second one is :code:`tile_x` with a same list of possible "
"values. These two knobs are independent, so they span a search space with "
"size 25 = 5x5."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:209
msgid ""
"The configuration knobs are passed to the :code:`split` schedule operation, "
"allowing us to schedule according to the 5x5 deterministic values we "
"previously defined in :code:`cfg`."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:214
msgid "A Matrix Multiplication Template with the Advanced Parameter API"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:215
msgid ""
"In the previous template, we manually listed all of the possible values for "
"a knob. This is the lowest level API to define the space, and gives an "
"explicit enumeration of the parameter space to search. However, we also "
"provide another set of APIs that can make the definition of the search space"
" easier and smarter. Where possible, we receomment you use this higher-level"
" API"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:221
msgid ""
"In the following example, we use :any:`ConfigSpace.define_split` to define a"
" split knob. It will enumerate all the possible ways to split an axis and "
"construct the space."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:225
msgid ""
"We also have :any:`ConfigSpace.define_reorder` for reorder knob and "
":any:`ConfigSpace.define_annotate` for annotation like unroll, "
"vectorization, thread binding. When the high level API cannot meet your "
"requirements, you can always fall back to using the low level API."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:269
msgid "More Explanation on :code:`cfg.define_split`"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:271
msgid ""
"In this template, :code:`cfg.define_split(\"tile_y\", y, num_outputs=2)` "
"will enumerate all possible combinations that can split axis y into two axes"
" with factors of the length of y. For example, if the length of y is 32 and "
"we want to split it into two axes using factors of 32, then there are 6 "
"possible values for (length of outer axis, length of inner axis) pair, "
"namely (32, 1), (16, 2), (8, 4), (4, 8), (2, 16) or (1, 32). These are all 6"
" possible values of `tile_y`."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:279
msgid ""
"During scheduling, :code:`cfg[\"tile_y\"]` is a :code:`SplitEntity` object. "
"We stores the lengths of outer axes and inner axes in "
":code:`cfg['tile_y'].size` (a tuple with two elements).  In this template, "
"we apply it by using :code:`yo, yi = cfg['tile_y'].apply(s, C, y)`. "
"Actually, this is equivalent to :code:`yo, yi = s[C].split(y, "
"cfg[\"tile_y\"].size[1])` or  :code:`yo, yi = s[C].split(y, "
"nparts=cfg['tile_y\"].size[0])`"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:287
msgid ""
"The advantage of using cfg.apply API is that it makes multi-level splits "
"(that is, when num_outputs >= 3) easier."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:291
msgid "Step 2: Use AutoTVM to Optimize the Matrix Multiplication"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:292
msgid ""
"In Step 1, we wrote a matrix multiplication template that allowed us to "
"paramaterize the block size used in the `split` schedule. We can now conduct"
" a search over this parameter space. The next step is to pick a tuner to "
"guide the exploration of this space."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:298
msgid "Auto-tuners in TVM"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:299
msgid "The job for a tuner can be described by following pseudo code"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:309
msgid ""
"When proposing the next batch of configs, the tuner can take different "
"strategies. Some of the tuner strategies provided by TVM include:"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:312
msgid ""
":any:`tvm.autotvm.tuner.RandomTuner`: Enumerate the space in a random order"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:313
msgid ""
":any:`tvm.autotvm.tuner.GridSearchTuner`: Enumerate the space in a grid "
"search order"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:314
msgid ""
":any:`tvm.autotvm.tuner.GATuner`: Using genetic algorithm to search through "
"the space"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:315
msgid ""
":any:`tvm.autotvm.tuner.XGBTuner`: Uses a model based method. Train a "
"XGBoost model to predict the speed of lowered IR and pick the next batch "
"according to the prediction."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:319
msgid ""
"You can choose the tuner according to the size of your space, your time "
"budget and other factors.  For example, if your space is very small (less "
"than 1000), a gridsearch tuner or a random tuner is good enough. If your "
"space is at the level of 10^9 (this is the space size of a conv2d operator "
"on CUDA GPU), XGBoostTuner can explore more efficiently and find better "
"configs."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:326
msgid "Begin tuning"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:327
msgid ""
"Here we continue our matrix multiplication example. First we create a tuning"
" task. We can also inspect the initialized search space. In this case, for a"
" 512x512 square matrix multiplication, the space size is 10x10=100 Note that"
" the task and search space are independent of the tuner picked."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:346
msgid "Out:"
msgstr "输出:"

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:357
msgid ""
"Then we need to define how to measure the generated code and pick a tuner. "
"Since our space is small, a random tuner is just okay."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:360
msgid ""
"We only make 10 trials in this tutorial for demonstration. In practice, you "
"can do more trials according to your time budget. We will log the tuning "
"results into a log file. This file can be used to choose the best "
"configuration discovered by the tuner later."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:379
msgid ""
"There are two steps for measuring a config: build and run. By default, we "
"use all CPU cores to compile program. We then measure them sequentially. To "
"help reduce variance, we take 5 measurements and average them."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:403
msgid ""
"With tuning completed, we can choose the configuration from the log file "
"that has the best measured performance and compile the schedule with the "
"corresponding parameters. We also do a quick verfication that the schedule "
"is producing correct answers.  We can call the function :code:`matmul` "
"directly under the :any:`autotvm.apply_history_best` context. When we call "
"this function, it will query the dispatch context with its argument and get "
"the best config with the same argument."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:438
msgid "Final Notes and Summary"
msgstr "最终说明总结"

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:439
msgid ""
"In this tutorial, we have shown how to build operator templates that allow "
"TVM to search a parameter space and choose optimized schedule "
"configurations. To gain a deeper understanding of how this works, we "
"recommend expanding on this example by adding new search parameters to the "
"schedule based on schedule operations demonstated in the `Getting Started "
"With Tensor Expressions <tensor_expr_get_started>_` tutorial. In the "
"upcoming sections, we will demonstate the AutoScheduler, a method for TVM to"
" optimize common operators without the need for the user to provide a user-"
"defined template."
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:461
msgid ""
":download:`Download Python source code: autotvm_matmul_x86.py "
"<autotvm_matmul_x86.py>`"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:467
msgid ""
":download:`Download Jupyter notebook: autotvm_matmul_x86.ipynb "
"<autotvm_matmul_x86.ipynb>`"
msgstr ""

#: ../../_staging/tutorial/autotvm_matmul_x86.rst:474
msgid ""
"`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr ""
"`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
